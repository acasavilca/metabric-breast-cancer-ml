<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Our GT CS7641 ML Project Page</title>
    <style>
        table, th, td {
            border: 1px solid black;
            border-collapse: collapse;
            padding: 8px;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
        }
        p {
            text-align: justify;
        }

        .pca-umap-block {
            display: flex;
            flex-wrap: wrap;
            gap: 40px;
            margin-bottom: 30px;
            justify-content: center;
            align-items: flex-start;
            /* font-family: Arial, sans-serif; */
        }

        .pca-block {
            width: 45%;
            min-width: 300px;
        }

        .umap-block {
            width: 45%;
            min-width: 300px;
        }

        .pca-block p {
            font-size: 14px;
            text-align: justify;
            margin-bottom: 10px;
        }

        .umap-block p {
            font-size: 14px;
            text-align: justify;
            margin-bottom: 25px;
        }

        .pca-block figure {
            text-align: center;
            margin: 0;
        }

        .umap-block figure {
            text-align: center;
            margin: 0;
        }

        .logistic-regression-hyperparam-table {
            border-collapse: collapse;
            width: 15%;
            /* margin: 20px auto; */
            margin-top: 10px;
            margin-left: 2.5%;
            background-color: #fff;
            font-family: Arial, sans-serif;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        .logistic-regression-hyperparam-table caption {
            caption-side: top;
            text-align: center;
            font-size: 0.8em;
            margin-bottom: 10px;
            font-weight: bold;
        }

        .logistic-regression-hyperparam-table th,
        .logistic-regression-hyperparam-table td {
            text-align: center;
            /* padding: 10px 14px; */
            border-bottom: 1px solid #ddd;
            font-size: 0.75em;
        }

        .logistic-regression-hyperparam-table th {
            background-color: #203f61;
            font-weight: bold;
            font-size: 0.8em;
            color:white;
        }

        .logistic-regression-hyperparam-table tr:hover {
            background-color: #f1faff;
        }

        .logistic-regression-metrics-container {
            display: flex;
            /* gap: 10px; */
            margin-bottom: 30px;
            justify-content: center;
            align-items: flex-start;
        }

        .logistic-regression-metrics-container figure,
        .logistic-regression-metrics-container .table-wrapper {
            width: 33%;
            text-align: center;
            box-sizing: border-box;
            margin-top: 10px;
        }

        .logistic-regression-metrics-container img {
            width: 100%;
            height: auto;
            display: block;
        }

        table.logistic-regression-classification-report {
            width: 100%;
            border-collapse: collapse;
            margin: 0 auto;
            font-family: Arial, sans-serif;
            font-size: 13px;
        }

        table.logistic-regression-classification-report th,
        table.logistic-regression-classification-report td {
            border: 1px solid #ccc;
            padding: 6px 8px;
            text-align: center;
        }

        table.logistic-regression-classification-report th {
            background-color: #03376e;
            color:white;
        }

        table.logistic-regression-classification-report caption {
            font-weight: bold;
            margin-bottom: 6px;
            font-size: 14px;
        }

        .highlight {
            background-color: #f0f7ff;
            font-weight: bold;
            color:black
        }

        .gene-table {
            width: 80%;
            border-collapse: collapse;
            font-family: Arial, sans-serif;
            font-size: 13px;
            margin: 20px 0;
        }

        .gene-table caption {
            caption-side: top;
            font-size: 15px;
            font-weight: bold;
            text-align: center;
            margin-bottom: 10px;
        }

        .gene-table th {
            padding: 10px 12px;
            border: 1px solid #ddd;
            vertical-align: top;
            text-align: center;
            background-color: #203f61;
            color: white;
        }

        .gene-table td {
            padding: 10px 12px;
            border: 1px solid #ddd;
            vertical-align: top;
            text-align: justify;
        }

        /* .gene-table thead {
            background-color: #e6f2ff;
        } */

        .gene-table tbody tr:nth-child(even) {
            background-color: #f9f9f9;
        }

        .gene-table tbody tr:hover {
            background-color: #f1faff;
        }

    </style>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <h1>CS7641 Machine Learning - Group 3 Project</h1>
        <!-- <p><a href="https://youtu.be/glB5aJTne4Q" target="_blank" rel="noopener noreferrer" style="font-weight: bold;">Watch our video presentation!</a></p> -->
        <!-- <nav>
            <ul>
                <li><a href="#introduction">Introduction</a></li>
                <li><a href="#methods">Methods</a></li>
                <li><a href="#libraries">Libraries</a></li>
                <li><a href="#project goals">Project goals</a></li>
                <li><a href="#expected results">Expected results</a></li>
                <li><a href="#references">References</a></li>
                <li><a href="#contributions table">Contributions table</a></li>
                <li><a href="https://github.gatech.edu/lramirez65/CS7641_ML_group3" target="_blank" rel="noopener noreferrer">GitHub repository</a></li>
            </ul>
        </nav> -->
    </header>

    <main>
        <section id="introduction">
            <h2>Introduction</h2>
            <p>Breast cancer remains one of the most prevalent and life-threatening forms of cancer among women worldwide. Despite advancements in early detection and treatment, predicting patient outcomes and tailoring personalized therapies remains difficult due to the biological complexity of the disease. One of the key challenges in breast cancer management is the high degree of heterogeneity at both the clinical and molecular levels, which complicates prognosis and treatment decisions. However, gene expression profiling has emerged as a powerful tool to uncover the biological underpinnings of breast cancer heterogeneity and to predict clinical outcomes. The landmark study by Van ’t Veer et al. [1] demonstrated that gene expression signatures could be used to predict breast cancer prognosis, laying the groundwork for molecular subtyping and personalized therapy. Building on this, large-scale analyses, such as Curtis et al. [2], revealed novel breast cancer subgroups based on combined genomic and transcriptomic data, underscoring the complexity of the disease. Further research has highlighted the relationship between gene coexpression networks and clinical outcomes. For instance, Clarke et al. [3] performed large-scale coexpression analyses and found that specific transcriptional networks were significantly correlated with breast cancer survival. Such findings emphasize the value of moving beyond single-gene analyses toward understanding complex gene-gene interactions.</p>
            <p>Building on this body of work, this project leverages the <strong>METABRIC dataset</strong> [4], introduced by Curtis et al. [2], to build machine learning models for patient classification and outcome prediction. The dataset includes gene expression profiles and clinical data for nearly 2,000 breast cancer patients. The dataset provides detailed information on over 600 genes as well as clinical variables such as patient age, tumor size, hormone receptor status, and survival outcomes.</p>
            <!--<img src="images/ml_logo.png" alt="Machine Learning Logo" style="max-width: 300px;">-->
        </section>

        <section id="problem-statement">
            <h2>Problem Statement</h2>
                <p>
                    Breast cancer prognosis remains challenging due to the high clinical and molecular heterogeneity of the disease, limiting the effectiveness of generalized treatment approaches. While gene expression profiling has shown promise in stratifying patients and predicting outcomes, current methods often fail to capture the complexity of gene-gene interactions. This project aims to leverage the METABRIC dataset to develop machine learning models that integrate gene expression and clinical data for more accurate breast cancer patient classification and survival outcome prediction. Further, we hope to develop a machine learning model acceptable to the medical community, capable of classifying different types of breast cancer with high recall and precision.
                </p>

        </section>

        <section id="methodology">
            <h2>Proposed Methodology</h2>

            <h3>Basic Overview of Data:</h3>
            <p>
                The METABRIC dataset contains 30 clinical features, m-RNA expression levels (z-score scaled) for 489 genes and mutations (binary features) reported in 173 genes.
            </p>

            <h3>Target Column Selection:</h3>
            <p>
                Out of the 30 clinical features present in the dataset, the <strong>pam50 + claudin-low subtype</strong> column was treated as our target variable, over other columns such as cancer_type and cancer_type_detailed. 
            </p>

            <p>
                The granularity provided with the pam50 + claudin-low subtype column is much higher (classes including luminal A, luminal B, HER2-enriched, Basal-like, Claudin-low, and normal-like) than the other columns - cancer type (classes include breast cancer or breast sarcoma) or cancer type detailed (Breast Invasive Ductal Carcinoma, Breast Mixed Ductal and Lobular Carcinoma, Breast Invasive Lobular Carcinoma, Breast Invasive Mixed Mucinous Carcinoma and Metaplastic Breast Cancer).
            </p>


            <p>
                Moreover, the pam50 + claudin-low subtype provides molecular resolution to the problem, over the coarse binary classification provided by cancer_type or structural resolution (ductal, lobular) provided by cancer_type_detailed. The pam50 + claudin-low subtype shows direct association with the ‘aggressiveness’ of the cancer and can offer better biological insights in terms of treatment options.
            </p>
        </section>

        <section id="eda">
            <h2>Exploratory Data Analysis</h2>

                <strong> Clinical Data </strong>

                    <p>
                        <u>Histograms:</u> We plot stacked histograms for each column in the clinical areas subset to visually assess if these variables differ by breast cancer subtype. In doing this, we hoped to achieve the following two goals: (a) find clinical variables that differ between subtypes by visually spotting shifts in distributions between classes and (b) guide feature selection e.g., if distributions for all subtypes look identical, that feature may have low predictive power. In the interest of space, we only present results for the most relevant histograms.
                    </p>

                    <div style="display: flex; gap: 100px; margin-bottom: 30px;">
                        <figure style="text-align: center; width: 33%;">
                            <img src="figures/histogram-age-at-diagnosis.png" style="width: 100%; height: auto;">
                            <figcaption>Figure 1: Histogram for Age at Diagnosis</figcaption>
                        </figure>
                        <figure style="text-align: center; width: 33%;">
                            <img src="figures/histogram-mutation-count.png" style="width: 100%; height: auto;">
                            <figcaption>Figure 2: Histogram for Mutation Count</figcaption>
                        </figure>
                    </div>

                    <div style="display: flex; gap: 100px; margin-bottom: 30px;">
                        <figure style="text-align: center; width: 33%;">
                            <img src="figures/histogram-overall-survival-months.png" style="width: 100%; height: auto;">
                            <figcaption>Figure 3: Histogram for Overall Survival Months</figcaption>
                        </figure>
                        <figure style="text-align: center; width: 33%;">
                            <img src="figures/histogram-tumour-size.png" style="width: 100%; height: auto;">
                            <figcaption>Figure 4: Histogram for Tumour Size</figcaption>
                        </figure>
                    </div>

                    <ul>
                        <li>
                            Age at Diagnosis: For the “Basal” subtype, the age range is skewed to the left i.e., most of the data points are between 40 and 70. However, for the “LumB” subtype, we see that most of the data points are between 55 and 95.
                        </li>
                        <li>
                            Mutation count - For the ‘Normal’ and ‘Claudin-low’ subtypes, mutation count is skewed to the left. However, for the other subtypes, we see higher mutation counts.
                        </li>
                        <li>
                            Overall survival months: We see that this attribute is relatively identically distributed across all subtypes (skewed to the left). However, for the “Basal” subtype, the number of months is uniformly distributed, indicating that patients with this type are likely to survive longer.
                        </li>
                        <li>
                            Tumour size: We see that tumour size is identically distributed across all subtypes, which tells us that this attribute is independent of subtype.
                        </li>
                    </ul>
                    

                    <p>
                        <u>Boxplots:</u> Boxplots provide a compact visual to assess the distribution differences between classes. In addition, it provides a visual assessment on the number of outliers and skewness of the feature. Below are the boxplots for the selected four clinical features, 'Age at Diagnosis', 'Mutation count', 'Overall survival months', and 'Tumour size'
                    </p>

                    <div style="display: flex; gap: 100px; margin-bottom: 30px;">
                        <figure style="text-align: center; width: 33%;">
                            <img src="figures/boxplot-age-at-diagnosis.png" style="width: 100%; height: auto;">
                            <figcaption>Figure 5: Boxplot for Age at Diagnosis</figcaption>
                        </figure>

                        <figure style="text-align: center; width: 33%;">
                            <img src="figures/boxplot-mutation-count.png" style="width: 100%; height: auto;">
                            <figcaption>Figure 6: Boxplot for Mutation Count</figcaption>
                        </figure>
                    </div>

                    <div style="display: flex; gap: 100px; margin-bottom: 30px;">
                        <figure style="text-align: center; width: 33%;">
                            <img src="figures/boxplot-overall-survival-months.png" style="width: 100%; height: auto;">
                            <figcaption>Figure 7: Boxplot for Overall Survival Months</figcaption>
                        </figure>

                        <figure style="text-align: center; width: 33%;">
                            <img src="figures/boxplot-tumour-size.png" style="width: 100%; height: auto;">
                            <figcaption>Figure 8: Boxplot for Tumour Size</figcaption>
                        </figure>
                    </div>

                    <p>
                        <u>Pair Plots:</u> Pairplots can help in observing distributions of the feature and also provide spread of values based on the target classes when points are class-colored. It also provides a visual on the nature of the correlation between two features and this serves as a very important first step towards correlation handling.
                    </p>

                    <figure style="text-align: center; width: 75%; height: 75%;">
                        <img src="figures/pairplot.png" style="width: 100%; height: auto;">
                        <figcaption>Figure 9: Pairplots</figcaption>
                    </figure>

                    <br> <br>
                
                <strong> Genes Data </strong>

                    <div class="pca-umap-block">
                        <div class="pca-block">
                            <p>
                            <u>Principal Components Analysis (PCA):</u> As the gene-data encompasses 400+ features, the genes data is linearly reduced to 2D dimensions and colored based on the classes. This visualization helps in understanding the underlying nature of the dataset.
                            </p>
                            <figure>
                            <img src="figures/pca-genes.png" alt="PCA for genes" style="width: 80%; height: auto;">
                            <figcaption>Figure 10: Principal Components Analysis for Genes Data</figcaption>
                            </figure>
                        </div>

                        <div class="umap-block">
                            <p>
                            <u>Uniform Manifold Approximation and Projection (UMAP):</u> Non-linear reduction of 400+ genes features to 2 components.
                            </p>
                            <figure>
                            <img src="figures/umap-genes.png" alt="UMAP for genes" style="width: 80%; height: auto;">
                            <figcaption>Figure 11: Uniform Manifold Approximation and Projection for Genes Data</figcaption>
                            </figure>
                        </div>
                    </div>

                    <p>
                        <u> Clustering:</u> This optional step was taken to assess the quality of genes data in addition to the above visual steps. 
                        Our motive here was to see how easy it is to separate the 7 classes we have with purely genes data in an unsupervised fashion. In this way, we can understand if there is an underlying pattern for any of the classes. If an unsupervised approach yields clusters similar to the ground truth, then a supervised model should be able to achieve a good performance as well.
                        If few clusters actually capture the ground-truth cluster/class, then a supervised model should perform well in classifying patients of this class inherently well than other classes.
                        In general, the number of genes present in such experiments are generally in the order of 10000. K-means, GMM, and any other distance metric based clustering algorithms may fail to perform well. 
                        In such cases, other approaches for clustering methods such as  Leiden and Louvain clustering (graph based approaches) are highly recommended. 
                        For simplicity, we tried K-means clustering on the 489 genes features present. Metrics such as adjusted rand index (ARI), normalized mutual information (NMI), homogeneity and completeness scores, and Fowlkes-Mallows index were computed to understand the quality of the clustering.
                    </p>
                    <div style="display: flex; gap: 100px; margin-bottom: 30px;">

                        <figure style="text-align: center; width: 33%; height: 33%;">
                            <img src="figures/umap-kmeans.png" style="width: 100%; height: auto;">
                            <figcaption>Figure 12: KMeans Clustering</figcaption>
                        </figure>

                        <figure style="text-align: center; width: 33%; height: 33%;">
                            <img src="figures/umap-gmm.png" style="width: 100%; height: auto;">
                            <figcaption>Figure 13: GMM Clustering</figcaption>
                        </figure>
                    </div>

                    <table border="1" cellpadding="5" cellspacing="0" style="margin-left: 30%">
                        <caption style="caption-side: top; font-weight: bold; margin-bottom: 10px;">
                            Table 1: Evaluation Metrics for KMeans and GMM Clustering
                        </caption>
                        <thead>
                            <tr>
                            <th>Metric</th>
                            <th>K-Means</th>
                            <th>GMM</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>ARI</td>
                                <td>0.20</td>
                                <td>0.17</td>
                            </tr>
                            <tr>
                                <td>NMI</td>
                                <td>0.30</td>
                                <td>0.18</td>
                            </tr>
                            <tr>
                                <td>Homogeneity</td>
                                <td>0.31</td>
                                <td>0.16</td>
                            </tr>
                            <tr>
                                <td>Completeness</td>
                                <td>0.30</td>
                                <td>0.20</td>
                            </tr>
                            <tr>
                                <td>V-Measure</td>
                                <td>0.30</td>
                                <td>0.18</td>
                            </tr>
                            <tr>
                                <td>Fowlkes-Mallows</td>
                                <td>0.37</td>
                                <td>0.41</td>
                            </tr>
                        </tbody>
                    </table>

        </section>

        <section id="feature-preprocessing">
            <h2>Feature Pre-processing</h2>

            <p>
                A robust feature preprocessing pipeline is created to handle missing values and outlier presence. Prior to any form of feature pre-processing, the dataset was split into training and test dataset (80% development dataset and 20% testing), to avoid data leakage.
            </p>

            <strong> Clinical Data </strong>

                <ol>
                    <li>
                        Imputation: The clinical data is a mixture of numerical (float64) and categorical (object) data types. They need to be handled separately. As clinical data is often MNAR [missing not at random] type, it can get tricky in choosing the best imputation method. Keeping this nature of MNAR data, we chose KNN imputer for numerical features and Mode imputer for categorical features.
                    </li>
                    <br>

                    <li>
                        Outlier Treatment: Models that heavily rely on distance metrics or linear assumptions are more sensitive to outliers than other models. It is thus advised to perform outlier treatment prior the learning process. 
                        To reduce the ill-effects of such noisy points on the model, the pipeline designed detects outliers through inter-quartile range (IQR) method. For a given numeric feature, if a value here falls outside the range (Q1-1.5*IQR , Q3+1.5*IQR), it is treated as an outlier.
                        If a value is below the lower limit, then it's value is augmented to lower limit and if the value is greater than the upper limit, then it is mapped to the upper limit. Such a method is referred as IQR clipping.
                    </li>
                    <br>

                    <li>
                        Scaling: The clinical dataset shows feature with varying magnitudes. If unscaled, features showing higher magnitudes [eg., age] can influence the model's learning over features of lower magnitudes (eg., tumor size). To overcome this unfairness, scaling of features provides an levelled ground where all features contribute to the model's learning process. In addition, the numerical stability of the model is improved.
                        In the pipeline developed, standard scaler is employed, and it maps the current range to a new range where the mean of the data is 0 and standard deviation is 1.
                    </li>
                    <br>

                    <li>
                        Correlation handling: To prevent models from failing and not reaching convergence due to singularity, we remove features that show linear dependence on other features, using correlation scores.
                    </li>
                    <br>

                    <li>
                        One-hot encoding of categorical data: As some models can not handle string forms of data, they need to be converted into a one-hot encoded form.
                    </li>

                </ol>
            
            <strong> Genes Data </strong>
                <p>
                    As the provided mRNA scores are already in the z-scores format, no data cleaning steps were applied on them.
                </p>
            
            <strong>Feature Selection using Mutual Information</strong>
                <p>
                    The cleaned clinical data and genes data are combined, giving us a huge number of features. Out of nearly 600 features, top 50 features were selected using the mutual information feature selector.
                    Those features include a higher population of gene-data and few clinical columns/features. The 50 features include: '3-gene_classifier_subtype_ER+/HER2- High Prolif', '3-gene_classifier_subtype_ER-/HER2-', 'acvrl1', 'adgra2', 'ahnak', 'aph1b', 'ar', 'aurka', 'bcl2', 'bmpr1b', 'ccnb1', 'ccnd2', 'ccne1', 'cdc25a', 'cdk1', 'cdk6', 'chek1', 'cyb5a', 'e2f2', 'e2f3', 'e2f4', 'e2f7', 'egfr', 'er_status_Negative', 'er_status_Positive', 'er_status_measured_by_ihc_Negative', 'er_status_measured_by_ihc_Positve', 'erbb2', 'erbb3', 'fancd2', 'gata3', 'hsd17b4', 'igf1r', 'integrative_cluster_10', 'kit', 'lama2', 'lfng', 'mapt', 'mmp12', 'mmp7', 'notch1', 'npnt', 'nras', 'nrip1', 'plagl1', 'pr_status_Positive', 'srd5a1', 'tgfb3', 'tgfbr2', 'ttyh1'
                </p>

        </section>

        <section id="model-building">
            <h2>Model Building</h2>

                <strong> Linear Models </strong>

                    <ul>
                        <li>
                            Logistic Regression
                        </li>
                    </ul>
                
                <strong> Tree-based Models </strong>

                    <ul>
                        <li>
                            Decision Tree
                        </li>
                        <br>

                        <li>
                            Random Forest
                        </li>
                        <br>

                        <li>
                            Gradient-boosted Decision Trees
                        </li>
                    </ul>
                
                <strong> Kernel-based Models </strong>

                    <ul>
                        <li>
                            Support Vector Machine
                        </li>
                    </ul>
        </section>

        <section id="metrics">
            <h2>Evaluation Metrics</h2>

                <ul>
                    <li>
                        AUROC
                    </li>
                    <br>

                    <li>
                        Precision
                    </li>
                    <br>

                    <li>
                        Recall
                    </li>
                    <br>

                    <li>
                        F1-Score
                    </li>
                    <br>

                    <li>
                        Confusion Matrix
                    </li>
                </ul>
        
        <section id="explainability">
            <h2>Model Explainability</h2>
                <ul>
                    <li>
                       Logistic regression: Using coefficients (magnitude and direction) to understand the contribution of each feature to the final prediction
                    </li>
                    <br>

                    <li>
                       Tree-based models: Using the inbuilt ‘feature_importance’ function, we can understand the contribution of each feature to the final prediction

                    </li>
                    <br>

                    <li>
                       SHAP analysis: A game-theory based, model-agonistic tool to provide a overview on the contributions of the features to the final prediction
                    </li>
                </ul>
        
        <section id="discussion">
            <h2> Discussion</h2>

                <h3> Exploratory Data Analysis</h3>

                <ol>
                    <li>
                       <u> UMAP vs PCA Visualization</u> 
                       <ul>
                            <li> UMAP showed much better separation of classes than PCA.</li>
                       </ul>
                    </li>
                    <br>
                    <div style="margin-left: 40px;">
                        <strong> Interpretation: </strong>

                            <ul>
                                <li>The data is non-linearly separable in its raw high-dimensional space</li>
                                <li>Linear techniques like PCA fail to capture the complex structure</li>
                            </ul>
                        <br>
                    </div>

                    <li>
                       <u> Clustering Before Supervised Learning</u>
                       <ul>
                            <li> Applied unsupervised clustering to explore inherent separability.</li>
                            <li> Compared clusters (generated without label knowledge) to true class labels.</li>
                            <li> Class 'Basal' cluster in K-means clustering is close to ground truth when we see the UMAP colored with k-means clusters vs groud truth </li>
                       </ul>
                    </li>
                    <br>

                    <div style="margin-left: 40px;">
                        <strong> Interpretation: </strong>

                            <ul>
                                <li>There is an underlying, intrinsic pattern in the data for at least class 'Basal'</li>
                                <li>Since class 'Basal' aligned naturally with data structure, it means class Basal datapoints emerge even without supervision.</li>
                                <li>For this class, a supervised model should perform well, as separability exists inherently.</li>
                            </ul>
                        <br>
                    </div>

                    <li>
                       <u> K-Means vs GMM Performance </u>
                       <ul>
                            <li> K-Means performed better than GMM in clustering alignment with ground truth.</li>
                            <li> GMM, which allows flexible, elliptical clusters, did not outperform the simpler, distance-based K-Means.</li>
                       </ul>
                    </li>
                    <br>
                    <div style="margin-left: 40px;">
                        <strong> Interpretation: </strong>

                            <ul>
                                <li>Cluster structure is compact, symmetric, and distance-driven rather than elongated or highly irregular</li>
                                <li>Euclidean distance reflects meaningful class similarity, which means supervised models that use euclidean distance should do well.</li>
                            </ul>
                    </div>
                </ol>

                <div id = "gene-data-understanding" style="margin-left: 40px;">
                    <h4> Overall Understanding of the genes-data </h4>

                        <ol>
                            <li>Non-linear structure is present, detected via UMAP's superior visualization.</li>
                            <li>Partial intrinsic class separation (class 'Basal') is evident from unsupervised clustering aligning with some ground truth labels.</li>
                            <li>Distance-based relationships dominate, supported by K-Means outperforming GMM.</li>
                            <li>There is potential for supervised learning success, especially for clearly separable classes.</li>
                            <li>Classes with poor separation in clustering may require more sophisticated, possibly non-linear models for effective classification.</li>
                        </ol>
                </div>

                <div id = "strategic-takeaways" style="margin-left: 40px;">
                
                    <h4> Strategic Takeaways </h4>

                        <ol>
                            <li>Explore non-linear supervised models (e.g., kernel SVM, tree-based ensembles, neural networks).</li>
                            <li>Distance-based approaches like k-NN may work well given the structure.</li>
                            <li>Focus on classes with poor unsupervised separation for targeted feature engineering or model optimization.</li>
                        </ol>
                </div>

                

                <h3> Models </h3>

                    <ol>
                        <li>
                            <strong> Logistic Regression </strong> 
                                
                                <ul>
                                    <br>
                                    <li>
                                        <u>Hyperparameters</u>: 

                                        <ol type="a">
                                            <li>
                                                Penalty: Type of regularization (L1, L2, or Elasticnet).
                                            </li>
                                            <li>
                                                Solver : Optimization algorithm used to fit the model (e.g., liblinear, saga)
                                            </li>
                                            <li>
                                                C: Inverse of regularization strength (smaller values show stronger regularization)
                                            </li>
                                            <li>
                                                Tolerance: Threshold for stopping the optimization loop
                                            </li>
                                            <li>
                                                Fit Intercept: Whether to use a non-zero intercept term
                                            </li>
                                            <li>
                                                Max iter: Maximum number of iterations allowed during the optimization process
                                            </li>
                                            <li>
                                                Multi-class: Method chosen for multi-class classification ('ovr' which builds multiple binary classifiers, 'multinomial' which uses softmax function)
                                            </li>
                                        </ol>

                                        <table class="logistic-regression-hyperparam-table">
                                            <!-- <caption>Hyperparameter Settings</caption> -->
                                            <tr>
                                                <th>Hyperparameter</th>
                                                <th>Value</th>
                                            </tr>
                                            <tr>
                                                <td>Penalty</td>
                                                <td>L2</td>
                                            </tr>
                                            <tr>
                                                <td>Solver</td>
                                                <td>Newton-cg</td>
                                            </tr>
                                            <tr>
                                                <td>C</td>
                                                <td>0.0464</td>
                                            </tr>
                                            <tr>
                                                <td>Tolerance</td>
                                                <td>0.0001</td>
                                            </tr>
                                            <tr>
                                                <td>Fit Intercept</td>
                                                <td>TRUE</td>
                                            </tr>
                                            <tr>
                                                <td>Max Iter</td>
                                                <td>1000</td>
                                            </tr>
                                            <tr>
                                                <td>Multi-class</td>
                                                <td>Multinomial</td>
                                            </tr>
                                        </table>
                                    </li>

                                    <br>
                                    <li>
                                        <u>Obtained metrics</u>: The model displays satisfactory results, with an overall testing AUROC of 0.949 and overall testing accuracy of 76%. The model shows high F1 scores per class (except class 'normal'), macro aggregated F1 score  and weighted F1 score, thus showing good discriminatory power. The class 'normal' shows the lowest F1 score. Upon studying the confusion matrix, the model seems to misclassify 'normal' cases as 'LumA', 'Claudin-low' or 'Her2'. Additionally, the model misclassifies 'LumA' instances as either 'normal' or 'LumB'. 
                                    </li>
                            
                                    <div class="logistic-regression-metrics-container">
                                        <figure>
                                            <img src="figures/logistic-regression-roc-curves.jpeg" alt="ROC curves">
                                            <!-- <figcaption>Figure 14: Logistic Regression ROC Curves</figcaption> -->
                                        </figure>

                                        <figure>
                                            <img src="figures/logistic-regression-confusion-matrix.png" alt="Confusion matrix">
                                            <!-- <figcaption>Figure 15: Logistic Regression Confusion Matrix</figcaption> -->
                                        </figure>

                                        <div class="table-wrapper">
                                            <table class="logistic-regression-classification-report">
                                            <caption>Classification Report (Weighted AUROC: 0.9475)</caption>
                                            <thead>
                                                <tr>
                                                <th>Class</th>
                                                <th>Precision</th>
                                                <th>Recall</th>
                                                <th>F1-Score</th>
                                                <th>Support</th>
                                                </tr>
                                            </thead>
                                            <tbody>
                                                <tr><td>Basal</td><td>0.85</td><td>0.78</td><td>0.82</td><td>37</td></tr>
                                                <tr><td>Her2</td><td>0.67</td><td>0.78</td><td>0.72</td><td>51</td></tr>
                                                <tr><td>LumA</td><td>0.85</td><td>0.73</td><td>0.78</td><td>127</td></tr>
                                                <tr><td>LumB</td><td>0.73</td><td>0.80</td><td>0.77</td><td>92</td></tr>
                                                <tr><td>Normal</td><td>0.56</td><td>0.61</td><td>0.58</td><td>31</td></tr>
                                                <tr><td>Claudin-low</td><td>0.82</td><td>0.79</td><td>0.81</td><td>39</td></tr>
                                                <tr class="highlight"><td>Accuracy</td><td colspan="3">0.76</td><td>377</td></tr>
                                                <tr class="highlight"><td>Macro Avg</td><td>0.75</td><td>0.75</td><td>0.75</td><td>377</td></tr>
                                                <tr class="highlight"><td>Weighted Avg</td><td>0.77</td><td>0.76</td><td>0.76</td><td>377</td></tr>
                                            </tbody>
                                            </table>
                                        </div>
                                    </div>

                                    <li>
                                        <u>Model Explainability</u>:
                                        
                                        <ul> 
                                            <br>
                                            <li>
                                                Coefficients/Feature importance for all classes: The plots below show the top 10 contributing features based on the absolute value of the coefficients. Using the coefficients plots obtained here, we will inspect the top 6 features and study if they agree with the clinical literature. In our study, we will dive deeper into model interpretation for only class 'Basal'. Basal-like subtype is the most aggressive and has the poorest prognosis among the breast cancer subtypes listed, with a 58% 5-year overall survival and frequent relapses 
                                            </li>
                                            <div style="display: flex; gap: 100px; margin-bottom: 30px;justify-content: center">
                                                <figure style="text-align: center; width: 75%; height: 75%;">
                                                    <img src="figures/logistic-regression-most-informative-features.png" style="width: 100%; height: auto;">
                                                    <figcaption>Figure 15: Logistic Regression Top 10 Most Informative Features Per Class</figcaption>
                                                </figure>
                                            </div>

                                            <li>
                                                Detailed study for class 'Basal' with plots and discussion/interpretation: Here, we examine the coefficients' signs and the nature of the features and see if they agree with clinical literature. To be specific, if the top feature is a gene, we observe if the coefficient sign for the gene is positive or not if the gene should be upregulated for class 'Basal' and coefficient sign is negative if the gene should be downregulated for class 'Basal'. If the top feature is a clinical feature, then we study clinical feature's nature (whether it's directly proportional to the aggressiveness of the cancer or inversely proportional). 
                                            </li>
                                            <br>

                                            <table class="gene-table">
                                                <caption>Gene-Level Insights with Clinical Relevance</caption>
                                                <thead>
                                                    <tr>
                                                    <th>Gene</th>
                                                    <th>Coefficient Sign</th>
                                                    <th>Role / Other Relevant Info</th>
                                                    <th>Coefficients' signs Matches Clinical Literature?</th>
                                                    </tr>
                                                </thead>
                                                <tbody>
                                                    <tr>
                                                    <td>nrip1</td>
                                                    <td>Negative</td>
                                                    <td>
                                                        High expression in Lum subtypes, supporting cell proliferation. Although not among the top ten genes in LumA/B in our model, they have the largest positive coefficients in these subtypes compared to the other subtypes [6].
                                                    </td>
                                                    <td>Yes. Known to be lowly expressed in basal-like subtype [6].</td>
                                                    </tr>
                                                    <tr>
                                                    <td>kit</td>
                                                    <td>Positive</td>
                                                    <td>
                                                        Tyrosine kinase growth factor, co-expressed with EGFR in basal-like subtypes [7].
                                                    </td>
                                                    <td>Yes. Overexpressed in basal-like subtype [7].</td>
                                                    </tr>
                                                    <tr>
                                                    <td>tgfbr2</td>
                                                    <td>Negative</td>
                                                    <td>
                                                        Tumor suppressor in normal tissue [8].<br>
                                                        Small, almost zero coefficient in “Normal” class in our model.
                                                    </td>
                                                    <td>
                                                        Yes. Low expression in basal-like tissue compared to normal tissue, but it’s also lowly expressed in other subtypes [8].
                                                    </td>
                                                    </tr>
                                                    <tr>
                                                    <td>nptnt</td>
                                                    <td>Negative</td>
                                                    <td>
                                                        Extracellular matrix protein involved in bone formation whose downregulation reduces metastatic spread to the bone [9].
                                                    </td>
                                                    <td>No clinical data supporting differential expression in the basal-like subtype.</td>
                                                    </tr>
                                                    <tr>
                                                    <td>chek1</td>
                                                    <td>Positive</td>
                                                    <td>
                                                        Promotes epithelial to mesenchymal transition (EMT) and enhances migration and invasion ability.<br>
                                                        Correlated with poor survival [10].
                                                    </td>
                                                    <td>Yes. Known to be upregulated and a marker for basal-like subtypes [10].</td>
                                                    </tr>
                                                    <tr>
                                                    <td>egfr</td>
                                                    <td>Positive</td>
                                                    <td>
                                                        Tyrosine kinase growth factor.<br>
                                                        Correlated with poor survival rate and frequent relapses.<br>
                                                        Overactivation results in aberrant signaling and uncontrolled cell growth and proliferation [11,12].
                                                    </td>
                                                    <td>Yes. Known to be overexpressed [11,12].</td>
                                                    </tr>
                                                </tbody>
                                            </table>

                                            <div style="display: flex; gap: 100px; margin-bottom: 30px;">
                                                <figure style="text-align: center; width: 75%; height: 75%;">
                                                    <img src="figures/logistic-regression-boxplots.jpeg" style="width: 100%; height: auto;">
                                                    <figcaption>Figure 16: Logistic Regression Boxplots for Top 6 Genes</figcaption>
                                                </figure>
                                            </div>

                                            The coefficient signs for the top 6 features (here, all 6 features are genes) and the nature of those genes (upregulated or downregulated) were consistent, showing that the model captures meaningful patterns and provides the predicted probability. The top six genes with the largest coefficients are consistent with clinical data, i.e., genes with large positive coefficients are known to be upregulated, while those with large negative coefficients are known to be downregulated. The exception was NPNT, whose large negative coefficient is not backed by clinical data, which does not describe any differential expression of this gene in basal-like subtype.
                                        </ul>
                                    </li>

                                </ul>
                        </li>
                    </ol>
        </section>


        
        <section id="references">
            <h2>References</h2>
            <ol>
                <li>
                    van 't Veer, L. J., Dai, H., Van De Vijver, M. J., He, Y. D., Hart, A. A. M., Mao, M., Peterse, H. L., Van Der Kooy, K., Marton, M. J., Witteveen, A. T., Schreiber, G. J., Kerkhoven, R. M., Roberts, C., Linsley, P. S., Bernards, R., & Friend, S. H. (2002).Gene expression profiling predicts clinical outcome of breast cancer. Nature, 415(6871), 530–536. 
                    <a href="https://doi.org/10.1038/415530a" target="_blank" rel="noopener noreferrer">https://doi.org/10.1038/415530a</a>
                </li>
                <li>
                    Curtis, C., Shah, S. P., Chin, S.-F., Turashvili, G., Rueda, O. M., Dunning, M. J., Speed, D., Lynch, A. G., Samarajiwa, S., Yuan, Y., Gräf, S., Ha, G., Haffari, G., Bashashati, A., Russell, R., McKinney, S., Langerød, A., Green, A., Provenzano, E., Wishart, G., Pinder, S., Watson, P., Markowetz, F., Murphy, L., Ellis, I., Purushotham, A., Børresen-Dale, A.-S., Brenton, J. D., Tavaré, S., Caldas, C., & Aparicio, S. (2012). The genomic and transcriptomic architecture of 2,000 breast tumours reveals novel subgroups. Nature, 486(7403), 346–352. 
                    <a href="https://doi.org/10.1038/nature10983" target="_blank" rel="noopener noreferrer">https://doi.org/10.1038/nature10983</a>
                </li>
                <li>
                    Clarke, C., Madden, S. F., Doolan, P., Aherne, S. T., Joyce, H., O’Driscoll, L., Gallagher, W. M., Hennessy, B. T., Moriarty, M., Crown, J., Kennedy, S., & Clynes, M. (2013). Correlating transcriptional networks to breast cancer survival: A large-scale coexpression analysis. Carcinogenesis, 34(10), 2300–2308. 
                    <a href="https://doi.org/10.1093/carcin/bgt208" target="_blank" rel="noopener noreferrer">https://doi.org/10.1093/carcin/bgt208</a>
                </li>
                <li>
                    <a href="https://www.kaggle.com/datasets/raghadalharbi/breast-cancer-gene-expression-profiles-metabric/data" target="_blank" rel="noopener noreferrer">METABRIC Dataset</a>
                </li>

                <li>
                    Bertucci, F., Finetti, P. & Birnbaum, D. Basal Breast Cancer: A Complex and Deadly Molecular Subtype. Curr. Mol. Med. 12, 96-110 (2012).
                </li>

                <li>
                    Aziz, M. H. et al. Suppressing NRIP1 inhibits growth of breast cancer cells in vitro and in vivo. Oncotarget 6, 39714-39724 (2015).
                </li>
                    
                <li>
                    Nalwoga, H., Arnes, J. B., Wabinga, H. & Akslen, L. A. Expression of EGFR and c-kit is associated with the basal-like phenotype in breast carcinomas of African women. APMIS Acta Pathol. Microbiol. Immunol. Scand. 116, 515-525 (2008).
                </li>
                    
                <li>
                    Chen, C. et al. TGFβ isoforms and receptors mRNA expression in breast tumours: prognostic value and clinical implications. BMC Cancer 15, 1010 (2015).
                </li>
                    
                <li>
                    Wang, D. et al. NPNT promotes early-stage bone metastases in breast cancer by regulation of the osteogenic niche. J. Bone Oncol. 13, 91-96 (2018).
                </li>
                    
                <li>
                    Kim, H.-J., Seo, B.-G., Seo, E.-C., Lee, K.-M. & Hwangbo, C. Checkpoint Kinase 1 (CHK1) Functions as Both a Diagnostic Marker and a Regulator of Epithelial-to-Mesenchymal Transition (EMT) in Triple-Negative Breast Cancer. Curr. Issues Mol. Biol. 44, 5848-5865 (2022).
                </li>
                    
                <li>
                    Park, H. S. et al. High EGFR gene copy number predicts poor outcome in triple-negative breast cancer. Mod. Pathol. 27, 1212-1222 (2014).
                </li>

                <li>
                    Leidy, J., Khan, A. & Kandil, D. Basal-Like Breast Cancer: Update on Clinicopathologic, Immunohistochemical, and Molecular Features. Arch. Pathol. Lab. Med. 138, 37-43 (2014).
                </li>
            </ol>
            </section>
        <section id="contributions table">
            <h2>Contributions table</h2>
            <table>
                <tr>
                    <th>Name</th>
                    <th>Contribution</th>
                </tr>
                <tr>
                    <td>Abhishek Vijeev</td>
                    <td>EDA, data pre-processing, website</td>
                </tr>
                <tr>
                    <td>Celine M Al-Noubani</td>
                    <td>EDA, data pre-processing</td>
                </tr>
                <tr>
                    <td>FNU Naga Nishkala</td>
                    <td>EDA, data pre-processing</td>
                </tr>
                <tr>
                    <td>Luis Andrés Casavilca</td>
                    <td>Logistic Regression, GitHub</td>
                </tr>
                <tr>
                    <td>Nikhil Sundaram</td>
                    <td>Logistic Regression</td>
                </tr>
                </table>
            </section>
        <p><a href="ML_Project_Gantt.xlsx" download  style="font-weight: bold;">Gantt chart</a></p>
    </main>

    <footer>
        <p>Created by CS7641-ML Group 3 on June 13, 2025</p>
    </footer>

</body>
</html>
