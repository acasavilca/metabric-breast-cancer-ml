<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Our GT CS7641 ML Project Page</title>
    <style>
        table, th, td {
            border: 1px solid black;
            border-collapse: collapse;
            padding: 8px;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
        }
        p {
            text-align: justify;
        }
    </style>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <h1>CS7641 Machine Learning - Group 3 Project</h1>
        <!-- <p><a href="https://youtu.be/glB5aJTne4Q" target="_blank" rel="noopener noreferrer" style="font-weight: bold;">Watch our video presentation!</a></p> -->
        <!-- <nav>
            <ul>
                <li><a href="#introduction">Introduction</a></li>
                <li><a href="#methods">Methods</a></li>
                <li><a href="#libraries">Libraries</a></li>
                <li><a href="#project goals">Project goals</a></li>
                <li><a href="#expected results">Expected results</a></li>
                <li><a href="#references">References</a></li>
                <li><a href="#contributions table">Contributions table</a></li>
                <li><a href="https://github.gatech.edu/lramirez65/CS7641_ML_group3" target="_blank" rel="noopener noreferrer">GitHub repository</a></li>
            </ul>
        </nav> -->
    </header>

    <main>
        <section id="introduction">
            <h2>Introduction</h2>
            <p>Breast cancer remains one of the most prevalent and life-threatening forms of cancer among women worldwide. Despite advancements in early detection and treatment, predicting patient outcomes and tailoring personalized therapies remains difficult due to the biological complexity of the disease. One of the key challenges in breast cancer management is the high degree of heterogeneity at both the clinical and molecular levels, which complicates prognosis and treatment decisions. However, gene expression profiling has emerged as a powerful tool to uncover the biological underpinnings of breast cancer heterogeneity and to predict clinical outcomes. The landmark study by Van ’t Veer et al. [1] demonstrated that gene expression signatures could be used to predict breast cancer prognosis, laying the groundwork for molecular subtyping and personalized therapy. Building on this, large-scale analyses, such as Curtis et al. [2], revealed novel breast cancer subgroups based on combined genomic and transcriptomic data, underscoring the complexity of the disease. Further research has highlighted the relationship between gene coexpression networks and clinical outcomes. For instance, Clarke et al. [3] performed large-scale coexpression analyses and found that specific transcriptional networks were significantly correlated with breast cancer survival. Such findings emphasize the value of moving beyond single-gene analyses toward understanding complex gene-gene interactions.</p>
            <p>Building on this body of work, this project leverages the <strong>METABRIC dataset</strong> [4], introduced by Curtis et al. [2], to build machine learning models for patient classification and outcome prediction. The dataset includes gene expression profiles and clinical data for nearly 2,000 breast cancer patients. The dataset provides detailed information on over 600 genes as well as clinical variables such as patient age, tumor size, hormone receptor status, and survival outcomes.</p>
            <!--<img src="images/ml_logo.png" alt="Machine Learning Logo" style="max-width: 300px;">-->
        </section>

        <section id="problem-statement">
            <h2>Problem Statement</h2>
                <p>
                    Breast cancer prognosis remains challenging due to the high clinical and molecular heterogeneity of the disease, limiting the effectiveness of generalized treatment approaches. While gene expression profiling has shown promise in stratifying patients and predicting outcomes, current methods often fail to capture the complexity of gene-gene interactions. This project aims to leverage the METABRIC dataset to develop machine learning models that integrate gene expression and clinical data for more accurate breast cancer patient classification and survival outcome prediction. Further, we hope to develop a machine learning model acceptable to the medical community, capable of classifying different types of breast cancer with high recall and precision.
                </p>

        </section>

        <section id="methodology">
            <h2>Proposed Methodology</h2>

            <h3>Basic Overview of Data:</h3>
            <p>
                The METABRIC dataset contains 30 clinical features, m-RNA expression levels (z-score scaled) for 489 genes and mutations (binary features) reported in 173 genes.
            </p>

            <h3>Target Column Selection:</h3>
            <p>
                Out of the 30 clinical features present in the dataset, the <strong>pam50 + claudin-low subtype</strong> column was treated as our target variable, over other columns such as cancer_type and cancer_type_detailed. 
            </p>

            <p>
                The granularity provided with the pam50 + claudin-low subtype column is much higher (classes including luminal A, luminal B, HER2-enriched, Basal-like, Claudin-low, and normal-like) than the other columns - cancer type (classes include breast cancer or breast sarcoma) or cancer type detailed (Breast Invasive Ductal Carcinoma, Breast Mixed Ductal and Lobular Carcinoma, Breast Invasive Lobular Carcinoma, Breast Invasive Mixed Mucinous Carcinoma and Metaplastic Breast Cancer).
            </p>


            <p>
                Moreover, the pam50 + claudin-low subtype provides molecular resolution to the problem, over the coarse binary classification provided by cancer_type or structural resolution (ductal, lobular) provided by cancer_type_detailed. The pam50 + claudin-low subtype shows direct association with the ‘aggressiveness’ of the cancer and can offer better biological insights in terms of treatment options.
            </p>
        </section>

        <section id="eda">
            <h2>Exploratory Data Analysis</h2>

                <strong> Clinical Data </strong>

                    <p>
                        <u>Histograms:</u> We plot stacked histograms for each column in the clinical areas subset to visually assess if these variables differ by breast cancer subtype. In doing this, we hoped to achieve the following two goals: (a) find clinical variables that differ between subtypes by visually spotting shifts in distributions between classes and (b) guide feature selection e.g., if distributions for all subtypes look identical, that feature may have low predictive power. In the interest of space, we only present results for the most relevant histograms.
                    </p>

                    <div style="display: flex; gap: 150px; margin-bottom: 30px;">
                        <img src="figures/histogram-age-at-diagnosis.png" height="33%" width="33%">
                        <img src="figures/histogram-mutation-count.png" height="33%" width="33%">
                    </div>

                    <div style="display: flex; gap: 150px; margin-bottom: 30px;">
                        <img src="figures/histogram-overall-survival-months.png" height="33%" width="33%">
                        <img src="figures/histogram-tumour-size.png" height="33%" width="33%">
                    </div>

                    <ul>
                        <li>
                            Age at Diagnosis: For the “Basal” subtype, the age range is skewed to the left i.e., most of the data points are between 40 and 70. However, for the “LumB” subtype, we see that most of the data points are between 55 and 95.
                        </li>
                        <li>
                            Mutation count - For the ‘Normal’ and ‘Claudin-low’ subtypes, mutation count is skewed to the left. However, for the other subtypes, we see higher mutation counts.
                        </li>
                        <li>
                            Overall survival months: We see that this attribute is relatively identically distributed across all subtypes (skewed to the left). However, for the “Basal” subtype, the number of months is uniformly distributed, indicating that patients with this type are likely to survive longer.
                        </li>
                        <li>
                            Tumour size: We see that tumour size is identically distributed across all subtypes, which tells us that this attribute is independent of subtype.
                        </li>
                    </ul>
                    

                    <p>
                        <u>Boxplots:</u> Boxplots provide a compact visual to assess the distribution differences between classes. In addition, it provides a visual assessment on the number of outliers and skewness of the feature. Below are the boxplots for the selected four clinical features, 'Age at Diagnosis', 'Mutation count', 'Overall survival months', and 'Tumour size'
                    </p>

                    <div style="display: flex; gap: 150px; margin-bottom: 30px;">
                        <img src="figures/boxplot-age-at-diagnosis.png" height="33%" width="33%">
                        <img src="figures/boxplot-mutation-count.png" height="33%" width="33%">
                    </div>

                    <div style="display: flex; gap: 150px; margin-bottom: 30px;">
                        <img src="figures/boxplot-overall-survival-months.png" height="33%" width="33%">
                        <img src="figures/boxplot-tumour-size.png" height="33%" width="33%">
                    </div>

                    <p>
                        <u>Pair Plots:</u> Pairplots can help in observing distributions of the feature and also provide spread of values based on the target classes when points are class-colored. It also provides a visual on the nature of the correlation between two features and this serves as a very important first step towards correlation handling.
                    </p>
                    <img src="figures/pairplot.png" height="75%" width="75%">

                    <br> <br>
                
                <strong> Genes Data </strong>

                    <p>
                        <u>Principal Components Analysis (PCA): </u> As the gene-data encompasses 400+ features, the genes data is linearly reduced to 2D dimensions and colored based on the classes. This visualization helps in understanding the underlying nature of the dataset.
                    </p>
                    <img src="figures/pca-genes.png" height="33%" width="33%">

                    <p>
                        <u> Uniform Manifold Approximation and Projection (UMAP): </u> Non-linear reduction of 400+ genes features to 2 components.
                    </p>
                    <img src="figures/umap-genes.png" height="33%" width="33%">

                    <p>
                        <u> Clustering:</u> This optional step was taken to assess the quality of genes data in addition to the above visual steps. 
                        Our motive here was to see how easy it is to separate the 7 classes we have with purely genes data in an unsupervised fashion. In this way, we can understand if there is an underlying pattern for any of the classes. If an unsupervised approach yields clusters similar to the ground truth, then a supervised model should be able to achieve a good performance as well.
                        If few clusters actually capture the ground-truth cluster/class, then a supervised model should perform well in classifying patients of this class inherently well than other classes.
                        In general, the number of genes present in such experiments are generally in the order of 10000. K-means, GMM, and any other distance metric based clustering algorithms may fail to perform well. 
                        In such cases, other approaches for clustering methods such as  Leiden and Louvain clustering (graph based approaches) are highly recommended. 
                        For simplicity, we tried K-means clustering on the 489 genes features present. Metrics such as adjusted rand index (ARI), normalized mutual information (NMI), homogeneity and completeness scores, and Fowlkes-Mallows index were computed to understand the quality of the clustering.
                    </p>
                    <div style="display: flex; gap: 150px; margin-bottom: 30px;">
                        <img src="figures/umap-kmeans.png" height="33%" width="33%">
                        <img src="figures/umap-gmm.png" height="33%" width="33%">
                    </div>

                    <table border="1" cellpadding="5" cellspacing="0">
                        <thead>
                            <tr>
                            <th>Metric</th>
                            <th>K-Means</th>
                            <th>GMM</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>ARI</td>
                                <td>0.20</td>
                                <td>0.17</td>
                            </tr>
                            <tr>
                                <td>NMI</td>
                                <td>0.30</td>
                                <td>0.18</td>
                            </tr>
                            <tr>
                                <td>Homogeneity</td>
                                <td>0.31</td>
                                <td>0.16</td>
                            </tr>
                            <tr>
                                <td>Completeness</td>
                                <td>0.30</td>
                                <td>0.20</td>
                            </tr>
                            <tr>
                                <td>V-Measure</td>
                                <td>0.30</td>
                                <td>0.18</td>
                            </tr>
                            <tr>
                                <td>Fowlkes-Mallows</td>
                                <td>0.37</td>
                                <td>0.41</td>
                            </tr>
                        </tbody>
                    </table>

        </section>

        <section id="feature-preprocessing">
            <h2>Feature Pre-processing</h2>

            <p>
                A robust feature preprocessing pipeline is created to handle missing values and outlier presence. Prior to any form of feature pre-processing, the dataset was split into training and test dataset (80% development dataset and 20% testing), to avoid data leakage.
            </p>

            <strong> Clinical Data </strong>

                <ol>
                    <li>
                        Imputation: The clinical data is a mixture of numerical (float64) and categorical (object) data types. They need to be handled separately. As clinical data is often MNAR [missing not at random] type, it can get tricky in choosing the best imputation method. Keeping this nature of MNAR data, we chose KNN imputer for numerical features and Mode imputer for categorical features.
                    </li>
                    <br>

                    <li>
                        Outlier Treatment: Models that heavily rely on distance metrics or linear assumptions are more sensitive to outliers than other models. It is thus advised to perform outlier treatment prior the learning process. 
                        To reduce the ill-effects of such noisy points on the model, the pipeline designed detects outliers through inter-quartile range (IQR) method. For a given numeric feature, if a value here falls outside the range (Q1-1.5*IQR , Q3+1.5*IQR), it is treated as an outlier.
                        If a value is below the lower limit, then it's value is augmented to lower limit and if the value is greater than the upper limit, then it is mapped to the upper limit. Such a method is referred as IQR clipping.
                    </li>
                    <br>

                    <li>
                        Scaling: The clinical dataset shows feature with varying magnitudes. If unscaled, features showing higher magnitudes [eg., age] can influence the model's learning over features of lower magnitudes (eg., tumor size). To overcome this unfairness, scaling of features provides an levelled ground where all features contribute to the model's learning process. In addition, the numerical stability of the model is improved.
                        In the pipeline developed, standard scaler is employed, and it maps the current range to a new range where the mean of the data is 0 and standard deviation is 1.
                    </li>
                    <br>

                    <li>
                        Correlation handling: To prevent models from failing and not reaching convergence due to singularity, we remove features that show linear dependence on other features, using correlation scores.
                    </li>
                    <br>

                    <li>
                        One-hot encoding of categorical data: As some models can not handle string forms of data, they need to be converted into a one-hot encoded form.
                    </li>

                </ol>
            
            <strong> Genes Data </strong>
                <p>
                    As the provided mRNA scores are already in the z-scores format, no data cleaning steps were applied on them.
                </p>
            
            <strong>Feature Selection using Mutual Information</strong>
                <p>
                    The cleaned clinical data and genes data are combined, giving us a huge number of features. Out of nearly 600 features, top 50 features were selected using the mutual information feature selector.
                    Those features include a higher population of gene-data and few clinical columns/features. The 50 features include: '3-gene_classifier_subtype_ER+/HER2- High Prolif', '3-gene_classifier_subtype_ER-/HER2-', 'acvrl1', 'adgra2', 'ahnak', 'aph1b', 'ar', 'aurka', 'bcl2', 'bmpr1b', 'ccnb1', 'ccnd2', 'ccne1', 'cdc25a', 'cdk1', 'cdk6', 'chek1', 'cyb5a', 'e2f2', 'e2f3', 'e2f4', 'e2f7', 'egfr', 'er_status_Negative', 'er_status_Positive', 'er_status_measured_by_ihc_Negative', 'er_status_measured_by_ihc_Positve', 'erbb2', 'erbb3', 'fancd2', 'gata3', 'hsd17b4', 'igf1r', 'integrative_cluster_10', 'kit', 'lama2', 'lfng', 'mapt', 'mmp12', 'mmp7', 'notch1', 'npnt', 'nras', 'nrip1', 'plagl1', 'pr_status_Positive', 'srd5a1', 'tgfb3', 'tgfbr2', 'ttyh1'
                </p>

        </section>

        <section id="model-building">
            <h2>Model Building</h2>

                <strong> Linear Models </strong>

                    <ul>
                        <li>
                            Logistic Regression
                        </li>
                    </ul>
                
                <strong> Tree-based Models </strong>

                    <ul>
                        <li>
                            Decision Tree
                        </li>
                        <br>

                        <li>
                            Random Forest
                        </li>
                        <br>

                        <li>
                            Gradient-boosted Decision Trees
                        </li>
                    </ul>
                
                <strong> Kernel-based Models </strong>

                    <ul>
                        <li>
                            Support Vector Machine
                        </li>
                    </ul>
        </section>

        <section id="metrics">
            <h2>Evaluation Metrics</h2>

                <ul>
                    <li>
                        AUROC
                    </li>
                    <br>

                    <li>
                        Precision
                    </li>
                    <br>

                    <li>
                        Recall
                    </li>
                    <br>

                    <li>
                        F1-Score
                    </li>
                    <br>

                    <li>
                        Confusion Matrix
                    </li>
                </ul>
        
        <section id="explainability">
            <h2>Model Explainability</h2>
                <ul>
                    <li>
                       Logistic regression: Using coefficients (magnitude and direction) to understand the contribution of each feature to the final prediction
                    </li>
                    <br>

                    <li>
                       Tree-based models: Using the inbuilt ‘feature_importance’ function, we can understand the contribution of each feature to the final prediction

                    </li>
                    <br>

                    <li>
                       SHAP analysis: A game-theory based, model-agonistic tool to provide a overview on the contributions of the features to the final prediction
                    </li>
                </ul>


        
        <section id="references">
            <h2>References</h2>
            <ol>
                <li>van 't Veer, L. J., Dai, H., Van De Vijver, M. J., He, Y. D., Hart, A. A. M., Mao, M., Peterse, H. L., Van Der Kooy, K., Marton, M. J., Witteveen, A. T., Schreiber, G. J., Kerkhoven, R. M., Roberts, C., Linsley, P. S., Bernards, R., & Friend, S. H. (2002).Gene expression profiling predicts clinical outcome of breast cancer. Nature, 415(6871), 530–536. 
                    <a href="https://doi.org/10.1038/415530a" target="_blank" rel="noopener noreferrer">https://doi.org/10.1038/415530a</a></li>
                <li>Curtis, C., Shah, S. P., Chin, S.-F., Turashvili, G., Rueda, O. M., Dunning, M. J., Speed, D., Lynch, A. G., Samarajiwa, S., Yuan, Y., Gräf, S., Ha, G., Haffari, G., Bashashati, A., Russell, R., McKinney, S., Langerød, A., Green, A., Provenzano, E., Wishart, G., Pinder, S., Watson, P., Markowetz, F., Murphy, L., Ellis, I., Purushotham, A., Børresen-Dale, A.-S., Brenton, J. D., Tavaré, S., Caldas, C., & Aparicio, S. (2012). The genomic and transcriptomic architecture of 2,000 breast tumours reveals novel subgroups. Nature, 486(7403), 346–352. 
                    <a href="https://doi.org/10.1038/nature10983" target="_blank" rel="noopener noreferrer">https://doi.org/10.1038/nature10983</a></li>
                <li>Clarke, C., Madden, S. F., Doolan, P., Aherne, S. T., Joyce, H., O’Driscoll, L., Gallagher, W. M., Hennessy, B. T., Moriarty, M., Crown, J., Kennedy, S., & Clynes, M. (2013). Correlating transcriptional networks to breast cancer survival: A large-scale coexpression analysis. Carcinogenesis, 34(10), 2300–2308. 
                    <a href="https://doi.org/10.1093/carcin/bgt208" target="_blank" rel="noopener noreferrer">https://doi.org/10.1093/carcin/bgt208</a></li>
                <li><a href="https://www.kaggle.com/datasets/raghadalharbi/breast-cancer-gene-expression-profiles-metabric/data" target="_blank" rel="noopener noreferrer">METABRIC Dataset</a></li>
            </ol>
            </section>
        <section id="contributions table">
            <h2>Contributions table</h2>
            <table>
                <tr>
                    <th>Name</th>
                    <th>Proposal Contribution</th>
                </tr>
                <tr>
                    <td>Abhishek Vijeev</td>
                    <td>Dataset discovery, introduction</td>
                </tr>
                <tr>
                    <td>Celine M Al-Noubani</td>
                    <td>Dataset discovery, video presentation</td>
                </tr>
                <tr>
                    <td>FNU Naga Nishkala</td>
                    <td>Exploratory data analysis, data pre-processing pipeline</td>
                </tr>
                <tr>
                    <td>Luis Andrés Casavilca</td>
                    <td>GitHub</td>
                </tr>
                <tr>
                    <td>Nikhil Sundaram</td>
                    <td>Gantt chart</td>
                </tr>
                </table>
            </section>
        <p><a href="ML_Project_Gantt.xlsx" download  style="font-weight: bold;">Gantt chart</a></p>
    </main>

    <footer>
        <p>Created by CS7641-ML Group 3 on June 13, 2025</p>
    </footer>

</body>
</html>
